{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Analysis Using GBRT on Central Car Auction Data\n",
    "\n",
    "**Data Source**\n",
    "Webpage:  http://www.centralcarauctions.com/trade/vehicles/price-guide/price-guide?page=1\n",
    "\n",
    "Date Accessed: July 2014 \n",
    "\n",
    "Analysis Method: Gradient Boosted Regression Trees (GBRT)\n",
    "\n",
    "Steps in this notebook: \n",
    "\n",
    "1. Read in prepreoced encoded data.   \n",
    "2. Perform a basic GBRT run and view Feature Importance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import ensemble, cross_validation as cv\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Coloring / Styling\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in Data file \n",
    "df_enc = pd.read_csv('cca_data_enc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select features\n",
    "features = ['model', 'year_ord', 'mileage', 'MOT_ord', 'make', 'class']\n",
    "target = ['price']\n",
    "\n",
    "# Extract Values\n",
    "X = df_enc[features].values.astype(float)\n",
    "y = df_enc[target].values.ravel().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>trim</th>\n",
       "      <th>class</th>\n",
       "      <th>year</th>\n",
       "      <th>mileage</th>\n",
       "      <th>MOT</th>\n",
       "      <th>price</th>\n",
       "      <th>MOT_ord</th>\n",
       "      <th>year_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>637 </th>\n",
       "      <td> 11</td>\n",
       "      <td> 315</td>\n",
       "      <td>           D - 1867CC</td>\n",
       "      <td> 27</td>\n",
       "      <td> 2004-03-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 2015-09-01 00:00:00</td>\n",
       "      <td> 825</td>\n",
       "      <td> 8</td>\n",
       "      <td>  73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td> 33</td>\n",
       "      <td> 313</td>\n",
       "      <td> DYN DCI 106 - 1461CC</td>\n",
       "      <td> 18</td>\n",
       "      <td> 2007-07-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 2015-03-01 00:00:00</td>\n",
       "      <td> 800</td>\n",
       "      <td> 2</td>\n",
       "      <td> 113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td> 43</td>\n",
       "      <td> 146</td>\n",
       "      <td>     SXI 16V - 1199CC</td>\n",
       "      <td>  6</td>\n",
       "      <td> 2004-03-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 2015-08-01 00:00:00</td>\n",
       "      <td> 160</td>\n",
       "      <td> 7</td>\n",
       "      <td>  73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td> 43</td>\n",
       "      <td> 388</td>\n",
       "      <td>    16V CLUB - 1598CC</td>\n",
       "      <td> 18</td>\n",
       "      <td> 2000-07-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 2015-08-01 00:00:00</td>\n",
       "      <td> 270</td>\n",
       "      <td> 7</td>\n",
       "      <td>  29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      make  model                  trim  class                 year  mileage  \\\n",
       "637     11    315            D - 1867CC     27  2004-03-01 00:00:00      NaN   \n",
       "2622    33    313  DYN DCI 106 - 1461CC     18  2007-07-01 00:00:00      NaN   \n",
       "3518    43    146      SXI 16V - 1199CC      6  2004-03-01 00:00:00      NaN   \n",
       "3700    43    388     16V CLUB - 1598CC     18  2000-07-01 00:00:00      NaN   \n",
       "\n",
       "                      MOT  price  MOT_ord  year_ord  \n",
       "637   2015-09-01 00:00:00    825        8        73  \n",
       "2622  2015-03-01 00:00:00    800        2       113  \n",
       "3518  2015-08-01 00:00:00    160        7        73  \n",
       "3700  2015-08-01 00:00:00    270        7        29  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enc[df_enc[features].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the Loss Function\n",
    "\n",
    "This section primarily looks at the effect of the differnt loss functions:\n",
    "\n",
    "* Least Absolute difference (lad)\n",
    "* Least Squares (ls)\n",
    "* A combination of the two above (huber)\n",
    "\n",
    "Each are investiagetd by running a 5 fold cross validation and visualising the residuals on each test set.\n",
    "\n",
    "Performace was measured using mean squared error (MSE) and mean absolute error (MAE) of the predictions on the test set. \n",
    "\n",
    "The huber loss function performed the best on this data with a combined Mean Absolute Error Score of **715.04** with standard deviation **52.94**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Model Batch Parameters\n",
    "params_list = [{'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 5,\n",
    "          'learning_rate': 0.1, 'loss': 'lad'}, \n",
    "               {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 5,\n",
    "          'learning_rate': 0.1, 'loss': 'ls'}, \n",
    "               {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 5,\n",
    "          'learning_rate': 0.1, 'loss': 'huber'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Parameter set 1: Loss function = lad\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8c79bf7562e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Initialise Regressor and fit training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Log Errors Over all consecutive iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chris/miniconda3/lib/python3.4/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, monitor)\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \"\"\"\n\u001b[1;32m   1393\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chris/miniconda3/lib/python3.4/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, monitor)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;31m# Check input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dense\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chris/miniconda3/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_arrays\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chris/miniconda3/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     41\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     42\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 43\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108c30898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialise Data Structures\n",
    "MSE_list = []\n",
    "MAE_list = []\n",
    "\n",
    "folds = 5\n",
    "\n",
    "for param_no, params in enumerate(params_list[:3]):\n",
    "    \n",
    "    print('\\nFor Parameter set {}: Loss function = {}\\n'.format(param_no + 1, params['loss']))\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    # K fold Cross Validation \n",
    "    kf = cv.KFold(X.shape[0], n_folds=folds, shuffle=True, random_state=111)\n",
    "    fold_count = 0    \n",
    "    for train_index, test_index in kf:    \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "       \n",
    "        # Initialise Regressor and fit training data \n",
    "        est = ensemble.GradientBoostingRegressor(**params)\n",
    "        est.fit(X_train, y_train)\n",
    "\n",
    "        # Log Errors Over all consecutive iterations  \n",
    "        train_error = est.train_score_\n",
    "        test_error = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "        for i, y_pred in enumerate(est.staged_predict(X_test)):\n",
    "            test_error[i] = est.loss_(y_test, y_pred)\n",
    "        \n",
    "        # Calculate mean of absolute error \n",
    "        mae = np.abs(y_test - est.predict(X_test)).mean()\n",
    "        # Calculate Std of absolute error \n",
    "        std_ae = np.abs(y_test - est.predict(X_test)).std()\n",
    "        \n",
    "        print(\"Fold %i: Mean Absolute Error: %0.2f   Std: %0.2f\" % (fold_count, mae, std_ae))\n",
    "        plt.plot(y_test - est.predict(X_test))\n",
    "        plt.title('Loss Funtion = {}'.format(params['loss']))\n",
    "        plt.xlabel('Test Instance')\n",
    "        plt.xlabel('Residual')\n",
    "        # Calculating mean results\n",
    "        mse = mean_squared_error(y_test, est.predict(X_test))\n",
    "        MSE_list.append(mse)\n",
    "        MAE_list.append(mae)\n",
    "        \n",
    "        fold_count += 1\n",
    "    \n",
    "    CV_MSE = np.array(MSE_list)\n",
    "    CV_MAE = np.array(MAE_list)\n",
    "    print(\"\\nAveraged Mean Absolute Error Scores: %0.2f    Std:  %0.2f\" % (CV_MAE.mean(), CV_MAE.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/chris/miniconda3/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m(43)\u001b[0;36m_assert_all_finite\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     42 \u001b[0;31m        raise ValueError(\"Input contains NaN, infinity\"\n",
      "\u001b[0m\u001b[0;32m---> 43 \u001b[0;31m                         \" or a value too large for %r.\" % X.dtype)\n",
      "\u001b[0m\u001b[0;32m     44 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> X\n",
      "array([[  4.30000000e+01,   1.33000000e+02,   3.86460000e+04,\n",
      "          2.00000000e+00,   0.00000000e+00,   6.00000000e+00],\n",
      "       [  1.10000000e+01,   1.06000000e+02,   8.11120000e+04,\n",
      "          9.00000000e+00,   1.00000000e+00,   6.00000000e+00],\n",
      "       [  1.10000000e+01,   8.60000000e+01,   5.97870000e+04,\n",
      "          4.00000000e+00,   1.00000000e+00,   1.70000000e+01],\n",
      "       ..., \n",
      "       [  3.77000000e+02,   1.09000000e+02,   7.40540000e+04,\n",
      "          4.00000000e+00,   4.50000000e+01,   1.60000000e+01],\n",
      "       [  3.77000000e+02,   1.09000000e+02,   7.79690000e+04,\n",
      "          1.30000000e+01,   4.50000000e+01,   1.60000000e+01],\n",
      "       [  3.77000000e+02,   1.09000000e+02,   6.89150000e+04,\n",
      "          2.00000000e+00,   4.50000000e+01,   1.60000000e+01]], dtype=float32)\n",
      "ipdb> X.max()\n",
      "nan\n",
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigting Deviance and Importance Plots\n",
    "\n",
    "Deviance plots track the error rate made with successive boosting iterations on both the training and test set.\n",
    "\n",
    "In addion, the frequency by which a learner split on a particular feature is extracted and used to show the relative importance of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-be7471f7ec00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Initialise Regressor and fit training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Log Errors Over all consecutive iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chris/miniconda3/lib/python3.4/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, monitor)\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \"\"\"\n\u001b[1;32m   1393\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chris/miniconda3/lib/python3.4/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, monitor)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;31m# Check input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dense\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chris/miniconda3/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_arrays\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chris/miniconda3/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     41\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     42\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 43\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Only look at one Partition of the  Data \n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y, random_state=0)\n",
    "\n",
    "### Model Batch Parameters\n",
    "params_list = [{'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 5,\n",
    "          'learning_rate': 0.1, 'loss': 'lad'}, \n",
    "               {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 5,\n",
    "          'learning_rate': 0.1, 'loss': 'ls'}, \n",
    "               {'n_estimators': 1000, 'max_depth': 3, 'min_samples_split': 5,\n",
    "          'learning_rate': 0.1, 'loss': 'huber'}]\n",
    "\n",
    "for params in params_list:\n",
    "    \n",
    "    # Initialise Regressor and fit training data \n",
    "    est = ensemble.GradientBoostingRegressor(**params)\n",
    "    est.fit(X_train, y_train)\n",
    "\n",
    "    # Log Errors Over all consecutive iterations  \n",
    "    train_error = est.train_score_\n",
    "    test_error = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "    for i, y_pred in enumerate(est.staged_predict(X_test)):\n",
    "        test_error[i] = est.loss_(y_test, y_pred)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, est.predict(X_test))\n",
    "    mae = mean_absolute_error(y_test, est.predict(X_test))\n",
    "    print(\"MAE: %.4f,   MSE: %.4f\" % (mae, mse))\n",
    "    print(\"Loss Function: {}\".format(params['loss']))\n",
    "    MSE_list.append(mse)\n",
    "    MAE_list.append(mae)    \n",
    "\n",
    "    # Plotting #\n",
    "    # -------- #\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Deviance')\n",
    "    plt.plot(np.arange(params['n_estimators']) + 1, est.train_score_, 'b-',\n",
    "             label='Training Set Deviance')\n",
    "    plt.plot(np.arange(params['n_estimators']) + 1, test_error, 'r-',\n",
    "             label='Test Set Deviance')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Boosting Iterations')\n",
    "    plt.ylabel('Deviance')\n",
    "\n",
    "    # Plot feature importance\n",
    "    feature_importance = est.feature_importances_\n",
    "    # make importances relative to max importance\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, np.array(features)[sorted_idx])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
